{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Install Libs","metadata":{"id":"qUd2GkDO6M7a"}},{"cell_type":"code","source":"!pip install wandb --upgrade\n!pip install pytorch-lightning\n!pip install albumentations\n!pip install python-dotenv\n!pip install torchmetrics\n!pip install gdown","metadata":{"id":"cTG5Q6H-6M75","outputId":"c888bcb0-aec9-4329-f726-36bcc59a8023","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.10.26)\nCollecting wandb\n  Downloading wandb-0.10.29-py2.py3-none-any.whl (2.1 MB)\n\u001b[K     |████████████████████████████████| 2.1 MB 2.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.14)\nRequirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.0)\nRequirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (5.3.1)\nRequirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (7.1.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\nRequirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.0.2)\nRequirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\nRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\nRequirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.1)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.1)\nRequirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.15.8)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\nRequirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\nInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.10.26\n    Uninstalling wandb-0.10.26:\n      Successfully uninstalled wandb-0.10.26\nSuccessfully installed wandb-0.10.29\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.7/site-packages (1.2.8)\nRequirement already satisfied: fsspec[http]>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (0.8.7)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (4.59.0)\nRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (0.18.2)\nRequirement already satisfied: PyYAML!=5.4.*,>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (5.3.1)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (1.7.0)\nRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (2.4.1)\nRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (1.19.5)\nRequirement already satisfied: torchmetrics>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (0.2.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.4.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.7.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.25.1)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.3)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.15.8)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (49.6.0.post20210108)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.26.1)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2020.12.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (1.26.4)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2.10)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.0.1)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->pytorch-lightning) (0.6)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (20.3.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (1.6.3)\nRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (5.1.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->fsspec[http]>=0.8.1->pytorch-lightning) (3.4.1)\nRequirement already satisfied: albumentations in /opt/conda/lib/python3.7/site-packages (0.5.2)\nRequirement already satisfied: imgaug>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.4.0)\nRequirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (4.5.1.48)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations) (5.3.1)\nRequirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.18.1)\nRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.19.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.5.4)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (7.2.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (3.4.1)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.5)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\nCollecting python-dotenv\n  Downloading python_dotenv-0.17.1-py2.py3-none-any.whl (18 kB)\nInstalling collected packages: python-dotenv\nSuccessfully installed python-dotenv-0.17.1\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.7/site-packages (0.2.0)\nRequirement already satisfied: torch>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.7.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (1.19.5)\nCollecting gdown\n  Downloading gdown-3.13.0.tar.gz (9.3 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.0.12)\nRequirement already satisfied: requests[socks]>=2.12.0 in /opt/conda/lib/python3.7/site-packages (from gdown) (2.25.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.59.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (1.26.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (1.7.1)\nBuilding wheels for collected packages: gdown\n  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gdown: filename=gdown-3.13.0-py3-none-any.whl size=9034 sha256=98f269b847954fe4b1fb5d74b1f10b59a179dba93f4242e34c37c3709338f0dc\n  Stored in directory: /root/.cache/pip/wheels/2f/2a/2f/86449b6bdbaa9aef873f68332b68be6bfbc386b9219f47157d\nSuccessfully built gdown\nInstalling collected packages: gdown\nSuccessfully installed gdown-3.13.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Download Dataset","metadata":{"id":"hRyEHAVr6M79"}},{"cell_type":"code","source":"#ID on Google Drive for -37,-27,-17 and -7dB transmit power datasets\nid_no = 3\ntpw_list = ['-37.3375dB','-27.3375dB','-17.3375dB','-7.3375dB']\ntpw = tpw_list[id_no]\nid_list = ['1MCW_V_qO8_zcAxE29sAHbY4p1483s0DH','18_LenmgNiQaOV2sNuYHlWlJ0tSNQpkXw','1mQCNp8dq499qnJI0YCc0hTVfmm4ppxO5','1JxAktCLpRkUC3Ylc736YsxwTQRTeIRnD']\nid_is = id_list[id_no]\nadd = \"https://drive.google.com/uc?id=\"\nurl = add+id_is\noutput = 'download.tar.gz'","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import gdown\ngdown.download(url, output, quiet=True)\n!tar -xvf download.tar.gz","metadata":{"id":"P3BpivW86M7_","outputId":"50151c07-25f5-473b-f570-224ffd5df7f3","trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"./Dataset_-7.3375dB/\n./Dataset_-7.3375dB/-7.3375dB_maxRateVal.npy\n./Dataset_-7.3375dB/-7.3375dB_trainOutLoc.npy\n./Dataset_-7.3375dB/-7.3375dB_inpTrain.npy\n./Dataset_-7.3375dB/-7.3375dB_highFreqChTrain.npy\n./Dataset_-7.3375dB/-7.3375dB_maxRateTrain.npy\n./Dataset_-7.3375dB/-7.3375dB_trainInpLoc.npy\n./Dataset_-7.3375dB/-7.3375dB_inpVal.npy\n./Dataset_-7.3375dB/-7.3375dB_valOutLoc.npy\n./Dataset_-7.3375dB/-7.3375dB_labelTrain.npy\n./Dataset_-7.3375dB/-7.3375dB_valInpLoc.npy\n./Dataset_-7.3375dB/-7.3375dB_labelVal.npy\n./Dataset_-7.3375dB/-7.3375dB_highFreqChVal.npy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Utils\n","metadata":{"id":"_Uvjb6Qy6M8A"}},{"cell_type":"code","source":"import glob\nimport os\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom PIL import Image\nfrom typing import Optional, Tuple\nimport pdb\n\n# def calc_acc(pred: torch.tensor, y: torch.tensor, num_classes: int, return_class_wise_acc: bool = False):    pred = pred.argmax(1)\n#     class_wise_acc = []\n#     for i in range(num_classes):\n#         tp = ((pred == i) & (y == i)).sum().float()\n#         tn = ((pred != i) & (y != i)).sum().float()\n#         fp = ((pred == i) & (y != i)).sum().float()\n#         fn = ((pred != i) & (y == i)).sum().float()\n#         acc = (tp + tn) / (tp + tn + fp + fn)\n#         class_wise_acc.append(acc)\n    \n# #     pdb.set_trace()\n#     class_wise_acc = torch.Tensor(class_wise_acc)\n#     if return_class_wise_acc:\n#         return class_wise_acc\n#     return class_wise_acc.mean()","metadata":{"id":"ySUctsbP6M8B","trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"GC3Y3gQ56M8C"}},{"cell_type":"code","source":"import glob\nimport os\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom PIL import Image\nfrom typing import Optional, Tuple","metadata":{"id":"bT9wU26w6M8D","trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class BeamPredictionDataset(Dataset):\n    \"\"\"Beam Prediction dataset.\"\"\"\n\n    def __init__(self, file_path: str,\n                 loc_file_path: str,\n                 label_file_path: str,\n                 reshape: bool=False,\n                 transforms: Optional[transforms.Compose] = None,\n                 preprocessing_fn: Optional[transforms.Compose] = None) -> None:\n        \"\"\"\n        Init the Dataset\n        \"\"\"\n        self.file_path = file_path\n        self.loc_file_path = loc_file_path\n        self.label_file_path = label_file_path\n        \n        self.data = np.concatenate((np.load(file_path),np.load(loc_file_path)[:-1,:]))\n        self.data = self.data.transpose((1, 0))\n        \n        self.label = np.load(label_file_path)\n#         pdb.set_trace()\n        \n        assert len(self.label) == len(self.data)\n        # reshape is true\n        # num_users x num_channels x num_antennas x real/imaginary\n        if reshape:\n            self.data = self.data.reshape((2, 4, 32, -1))\n            self.data = self.data.transpose((3, 2, 1, 0))\n            \n        self.preprocessing_fn = preprocessing_fn\n        self.transforms = transforms\n\n    def __len__(self) -> int:\n        \"\"\"\n        Returns the total length of dataset.\n        \"\"\"\n        return len(self.data)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Gets an item from dataset\n        \"\"\"\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        user_data = self.data[idx]\n        \n        if self.preprocessing_fn is not None:\n            user_data = self.preprocessing_fn(user_data)\n        \n        if self.transforms is not None:\n            user_data = self.transforms(user_data)\n        \n        label = self.label[idx]\n        label = torch.Tensor(label).type(torch.int64) - 1\n        return user_data, label\n    \ndef transform(x: np.array) -> torch.Tensor:\n    # mean normalize\n    x -= x.mean()\n    x /= x.std()\n    x = torch.Tensor(x)\n    return x","metadata":{"id":"hxlK0ula6M8E","trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"V47uyDo06M8G"}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nimport pytorch_lightning as pl\nimport wandb\nfrom argparse import ArgumentParser\nfrom typing import Tuple\nfrom torchmetrics import Accuracy, Precision, Recall\nfrom sklearn.metrics import confusion_matrix\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport pdb\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n#Defining Mish\nclass Mish(nn.Module):\n    def forward(self,x):\n        x = x * (torch.tanh(F.softplus(x)))\n        return x\n\nclass BeamClassifier(pl.LightningModule):\n\n    def __init__(self, hparams) -> None:\n        \"\"\"\n        Downloading Backbone and defining structure of model.\n        \"\"\"\n        super().__init__()\n        # args from argparser\n        self.hparams = hparams\n        in_ch = self.hparams.in_ch\n        out_ch = self.hparams.out_ch\n        dropout_prob = self.hparams.dropout_prob\n        \n        self.model = nn.Sequential(\n            nn.Linear(in_ch, 2048),\n            nn.BatchNorm1d(2048),\n            Mish(),\n            nn.Dropout(dropout_prob),\n            \n            nn.Linear(2048, 2048),\n            nn.BatchNorm1d(2048),\n            Mish(),\n            nn.Dropout(dropout_prob),\n            \n            nn.Linear(2048, 2048),\n            nn.BatchNorm1d(2048),\n            Mish(),\n            nn.Dropout(dropout_prob),\n            \n            nn.Linear(2048, 2048),\n            nn.BatchNorm1d(2048),\n            Mish(),\n            nn.Dropout(dropout_prob),\n            \n            nn.Linear(2048, 2048),\n            nn.BatchNorm1d(2048),\n            Mish(),\n            nn.Dropout(dropout_prob),\n            \n            nn.Linear(2048, out_ch),\n        )\n        \n        self._acc_metric = Accuracy()\n        self._top3_acc_metric = Accuracy(top_k=3)\n        self._precision = Precision(average='macro', \n                                   num_classes=self.hparams.out_ch)\n        self._recall = Recall(average='macro', \n                             num_classes=self.hparams.out_ch)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\" Forward step of model.\n        \"\"\"\n#       pdb.set_trace()\n        x = self.model(x)\n        return x\n\n    def loss_fn(self, pred: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Loss function used for model\"\"\"\n        y_sq = y.squeeze(-1)\n        loss = F.cross_entropy(pred, y_sq)\n        return loss\n    \n    def configure_optimizers(self) -> torch.optim:\n        # REQUIRED\n        # can return multiple optimizers and learning_rate schedulers\n        opt = torch.optim.Adam(self.model.parameters(),\n                               lr=self.hparams.learning_rate,weight_decay=self.hparams.weight_decay)\n        self.optimizer = opt\n        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=0.8, patience=3, threshold=0.0001)\n        self.lr_scheduler = lr_scheduler\n#         lr_scheduler = None\n        return {\n           'optimizer': opt,\n           'lr_scheduler': lr_scheduler,\n           'monitor': 'val_acc'\n       }\n\n    def train_dataloader(self) -> DataLoader:\n        \"\"\"Define the data loader for training data\"\"\"\n        # REQUIRED\n        return DataLoader(BeamPredictionDataset(\n                                file_path='./Dataset_'+tpw+'/'+tpw+'_inpTrain.npy',\n                                loc_file_path='./Dataset_'+tpw+'/'+tpw+'_trainInpLoc.npy',\n                                label_file_path='./Dataset_'+tpw+'/'+tpw+'_labelTrain.npy',\n                                transforms=transform\n                            ),\n                          batch_size=self.hparams.batch_size,\n                          num_workers=self.hparams.num_workers,\n                          shuffle=True)\n\n    def training_step(self, batch: list, batch_idx: int) -> dict:\n        \"\"\"Backward step of model\"\"\"\n        # REQUIRED\n        x, y = batch\n        pred = self.forward(x)\n\n        loss = self.loss_fn(pred, y)\n        \n        pred = F.softmax(pred, dim=-1)\n        y_sq = y.squeeze(-1)\n        \n        # metrics\n        acc = self._acc_metric(pred, y_sq)\n        prec = self._precision(pred, y_sq)\n        rec = self._recall(pred, y_sq)\n        \n        if self.lr_scheduler is not None:\n            lr = [group[\"lr\"] for group in self.optimizer.param_groups][0]\n\n        if(batch_idx % self.hparams.wandb_log_num_iter == 0):\n            wandb.log({\n                'train_loss': loss,\n            })\n            \n        return {\n            'loss': loss,\n            'train_acc': acc,\n            'train_prec': prec,\n            'train_rec': rec\n        }\n    \n    def training_epoch_end(self, outputs: list) -> None:\n        acc = torch.stack([x['train_acc'] for x in outputs]).mean()\n        prec = torch.stack([x['train_prec'] for x in outputs]).mean()\n        rec = torch.stack([x['train_rec'] for x in outputs]).mean()\n        \n        if self.lr_scheduler is not None:\n            lr = [group[\"lr\"] for group in self.optimizer.param_groups][0]\n        else:\n            lr = self.hparams.learning_rate\n        logs = {\n            'lr': lr,\n            'train_acc': acc,\n            'train_prec': prec,\n            'train_rec': rec\n        }\n        wandb.log(logs)\n        self.log_dict(logs)\n    \n    def val_dataloader(self) -> DataLoader:\n        \"\"\"Define the data loader for validation data\"\"\"\n        # OPTIONAL\n        return DataLoader(BeamPredictionDataset(\n                                file_path='./Dataset_'+tpw+'/'+tpw+'_inpVal.npy',\n                                loc_file_path='./Dataset_'+tpw+'/'+tpw+'_valInpLoc.npy',\n                                label_file_path='./Dataset_'+tpw+'/'+tpw+'_labelVal.npy',\n                                transforms=transform\n                            ),\n                          batch_size=self.hparams.batch_size,\n                          num_workers=self.hparams.num_workers\n                         )\n\n    def validation_step(self, batch: list, batch_idx: torch.Tensor) -> dict:\n        \"\"\"Validation step to be carried out on validation data.\"\"\"\n        # REQUIRED\n        # pdb.set_trace()\n        x, y = batch\n        \n        pred = self.forward(x)\n\n        loss = self.loss_fn(pred, y)\n        self.log('val_loss', loss)\n        \n        pred = F.softmax(pred, dim=-1)\n        y_sq = y.squeeze(-1)\n        \n        acc = self._acc_metric(pred, y_sq)\n        prec = self._precision(pred, y_sq)\n        rec = self._recall(pred, y_sq)\n\n        return {\n            'val_loss': loss,\n            'val_acc': acc,\n            'val_prec': prec,\n            'val_rec': rec\n        }\n\n    def validation_epoch_end(self, outputs: list) -> None:\n        \"\"\"Use results from each validation step to generate validation stats at epoch end\"\"\"\n        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n        val_prec = torch.stack([x['val_prec'] for x in outputs]).mean()\n        val_rec = torch.stack([x['val_rec'] for x in outputs]).mean()\n        \n        logs = {\n            'val_loss': val_loss,\n            'val_acc': val_acc,\n            'val_prec': val_prec,\n            'val_rec': val_rec\n        }\n        wandb.log(logs)\n        self.log_dict(logs)\n    \n    def test_dataloader(self) -> DataLoader:\n        \"\"\"Define the data loader for test data\"\"\"\n        print(\"Test Dataloader\")\n        # OPTIONAL\n        return DataLoader(BeamPredictionDataset(\n                                file_path='./Dataset_'+tpw+'/'+tpw+'_inpVal.npy',\n                                loc_file_path='./Dataset_'+tpw+'/'+tpw+'_valInpLoc.npy',\n                                label_file_path='./Dataset_'+tpw+'/'+tpw+'_labelVal.npy',\n                                transforms=transform\n                            ),\n                          batch_size=self.hparams.batch_size,\n                          num_workers=self.hparams.num_workers\n                         )\n    \n    def test_step(self, batch: list, batch_idx: torch.Tensor) -> dict:\n        \"\"\"Validation step to be carried out on validation data.\"\"\"\n        # REQUIRED\n        # pdb.set_trace()\n        x, y = batch\n        \n        pred = self.forward(x)        \n        pred = F.softmax(pred, dim=-1)\n        y_sq = y.squeeze(-1)\n        logs = {\n            'pred': pred,\n            'ground_truth': y_sq\n        }\n#         self.log_dict(logs)\n        return logs\n    \n    def test_epoch_end(self, outputs: list) -> None:\n        \"\"\"Use results from each validation step to generate validation stats at epoch end\"\"\"\n        pred = torch.cat([x['pred'] for x in outputs], dim=0)\n        ground_truth = torch.cat([x['ground_truth'] for x in outputs], dim=0)\n\n        top1_acc = self._acc_metric(pred, ground_truth)\n        top3_acc = self._top3_acc_metric(pred, ground_truth)\n        \n#         pdb.set_trace()\n        conf_matrix = confusion_matrix(ground_truth.tolist(), \n                                       pred.argmax(-1).tolist(), \n                                       labels=list(range(self.hparams.out_ch)))\n        df_cm = pd.DataFrame(conf_matrix, index = [str(i) for i in range(self.hparams.out_ch)],\n                  columns = [str(i) for i in range(self.hparams.out_ch)])\n        \n        plt.figure(figsize = (50,50))\n        ax = sns.heatmap(df_cm, annot=True)\n        logs = {\n            'top1_acc': top1_acc,\n            'top3_acc': top3_acc,\n            'conf_matrix': wandb.Image(ax)\n        }\n        wandb.log(logs)\n    \n\n    def load_encoder_weights(self) -> None:\n        \"\"\"Loads encoder weights from ckpt\"\"\"\n        ckpt = torch.load(self.hparams.encoder_ckpt_path)\n        pretrained_dict = ckpt['state_dict']\n        model_dict = self.state_dict()\n        pretrained_dict = {k: v for k, v in pretrained_dict.items() if (\n            'encoder' in k) and (k in model_dict)}\n        model_dict.update(pretrained_dict)\n        self.load_state_dict(model_dict)\n\n    def load_model_weights_from_ckpt(self) -> None:\n        \"\"\"Load model weights to model on cpu\"\"\"\n        ckpt = torch.load(self.hparams.model_ckpt_path,\n                          map_location=torch.device('cpu'))\n        pretrained_dict = ckpt['state_dict']\n        model_dict = self.state_dict()\n        pretrained_dict = {k: v for k,\n                           v in pretrained_dict.items() if (k in model_dict)}\n        model_dict.update(pretrained_dict)\n        self.load_state_dict(model_dict)\n        \n    def _get_learning_rate(self) -> float:\n        i = 0\n        for param_group in self._optimizer.param_groups:\n            if i == 0:\n                learning_rate = param_group[\"lr\"]\n            else:\n                if learning_rate != param_group[\"lr\"]:\n                    raise ValueError(\n                        \"different param groups have different lr\")\n        return learning_rate\n\n    @staticmethod\n    def add_model_specific_args(parent_parser: ArgumentParser) -> ArgumentParser:\n        \"\"\"\n        Specify the hyperparams for this LightningModule\n        \"\"\"\n        # MODEL specific arguments\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n        parser.add_argument('--learning_rate', default=0.02, type=float)\n        parser.add_argument('--batch_size', default=32, type=int)\n        parser.add_argument('--in_ch', default=256, type=int)\n        parser.add_argument('--out_ch', default=64, type=int)\n        parser.add_argument('--num_workers', default=1, type=int)\n        parser.add_argument('--dropout_prob', default=0.5, type=float)\n        parser.add_argument('--max_nb_epochs', default=1, type=int)\n        parser.add_argument('--weight_decay', default=0.0005, type=float)\n        return parser","metadata":{"id":"I_VRLMlf6M8H","trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from argparse import ArgumentParser, Namespace\nargs_str = [\n        # model related args\n        '--max_nb_epochs=1',\n        '--learning_rate=1e-4',\n        '--batch_size=16',\n        '--in_ch=258',\n        '--out_ch=64',\n        '--num_workers=2'\n]\nparser = ArgumentParser(add_help=False)\nparser = BeamClassifier.add_model_specific_args(parser)\nargs= parser.parse_args(args_str)\n\nmodel = BeamClassifier(args)\ntrain_dl = model.train_dataloader()\nit = iter(train_dl)\nx, y = next(it)\n\n\npred = model(x)\nloss = model.loss_fn(pred, y)\nprint(loss)","metadata":{"id":"_-87vNjb6M8W","outputId":"a95fefa2-9322-4448-8fbd-5def45022f3e","trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"tensor(4.2355, grad_fn=<NllLossBackward>)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Trainer","metadata":{"id":"fiWDaCDp6M8b"}},{"cell_type":"code","source":"args_str = ['--tpu_cores=0',\n        '--progress_bar_refresh_rate=20',\n        '--wandb_run_name=Baseline Location '+tpw,\n        '--wandb_project_name=Beam Prediction',\n        '--wandb_log_num_iter=1',\n        '--num_workers=8',\n        '--gpus=1',\n        # model related args\n        '--max_nb_epochs=100',\n        '--weight_decay=5e-5',\n        '--learning_rate=1e-4',\n        '--batch_size=256',\n        '--dropout_prob=0.3',\n        '--in_ch=258',\n        '--out_ch=64',\n    ]","metadata":{"id":"SqrrWNIW6M8c","trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning import Trainer, seed_everything\nfrom argparse import ArgumentParser, Namespace\nimport wandb\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom dotenv import load_dotenv\n\nPROJECT_ROOT = os.path.dirname(os.path.abspath('.'))\nload_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, '.env'))\n\n!wandb login 12f84ed3682e47836a736950196a7349421a6cbb\n#!wandb login --relogin\n#12f84ed3682e47836a736950196a7349421a6cbb\n# import pdb\n\nparser = ArgumentParser(add_help=False)\nparser.add_argument('-wandb_run_name',\n                '--wandb_run_name',\n                help='Name of Wandb Run',\n                default='run',\n                type=str)\nparser.add_argument('-wandb_project_name',\n                    '--wandb_project_name',\n                    help='Wandb Project Name',\n                    default='deep_dream',\n                    type=str)\nparser.add_argument('-model_ckpt_path',\n                    '--model_ckpt_path',\n                    help='Model Checkpoint Path',\n                    default='./ckpts/model.ckpt',\n                    type=str)\nparser.add_argument('-wandb_log_num_iter',\n                    '--wandb_log_num_iter',\n                    help='After how many batches, we will log in training loop',\n                    default=1,\n                    type=int)\nparser.add_argument('-init_ckpt',\n                    '--init_ckpt',\n                    help='Initial Ckpt',\n                    default=None,\n                    type=str)\n\ndef main(args):\n    \"\"\"Main function that will perform all the training\"\"\"\n    # init module\n    model = BeamClassifier(args)\n\n    # Using Wandblogger so that we can log our results to wandb\n    wandb.init(name=args.wandb_run_name,\n               project=args.wandb_project_name,\n               config=vars(args))\n        \n    wandb.watch(model)\n\n    # most basic trainer, uses good defaults\n    checkpoint_callback = ModelCheckpoint(\n        monitor='val_loss',\n        dirpath='./ckpts',\n        filename='{epoch:02d}-{val_loss:.2f}'\n    )\n\n    #early stopping\n    from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n    early_stop_callback = EarlyStopping(\n        monitor='val_loss',\n        min_delta=0.00,\n        patience=12,\n        verbose=False,\n        mode='min')\n\n    \n    \n    trainer = Trainer(logger=[], \n                      gpus=args.gpus, \n                      max_epochs=args.max_nb_epochs, \n                      resume_from_checkpoint=args.init_ckpt,\n                      callbacks=[early_stop_callback])\n#     pdb.set_trace()\n    trainer.fit(model)\n    trainer.test()\n    \n    ckpt_path = os.path.join('./ckpt', f\"{args.wandb_project_name}\", f\"{args.wandb_run_name}.ckpt\")\n    ckpt_base_path = os.path.dirname(ckpt_path)\n    trainer.save_checkpoint(ckpt_path)\n    wandb.save(ckpt_path)\n\n    return model\n\nif __name__ == '__main__':\n\n    # auto add args from trainer\n    parser = Trainer.add_argparse_args(parser)\n\n    # give the module a chance to add own params\n    # good practice to define LightningModule speficic params in the module\n    parser = BeamClassifier.add_model_specific_args(parser)\n\n    # parse params\n    args = parser.parse_args(args_str)\n\n    seed_everything(123)\n\n    model = main(args)","metadata":{"id":"Zcv7wxiD6M8d","outputId":"df86b54c-cfa0-444b-f08b-97d867ecf31f","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:3cfszrbn) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 429<br/>Program ended successfully."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 200.31MB of 200.31MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find user logs for this run at: <code>/kaggle/working/wandb/run-20210505_090748-3cfszrbn/logs/debug.log</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210505_090748-3cfszrbn/logs/debug-internal.log</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>val_loss</td><td>1.74303</td></tr><tr><td>val_acc</td><td>0.35296</td></tr><tr><td>val_prec</td><td>0.27521</td></tr><tr><td>val_rec</td><td>0.27729</td></tr><tr><td>_runtime</td><td>595</td></tr><tr><td>_timestamp</td><td>1620206264</td></tr><tr><td>_step</td><td>7801</td></tr><tr><td>train_loss</td><td>1.68155</td></tr><tr><td>lr</td><td>8e-05</td></tr><tr><td>train_acc</td><td>0.44391</td></tr><tr><td>train_prec</td><td>0.38692</td></tr><tr><td>train_rec</td><td>0.39007</td></tr><tr><td>top1_acc</td><td>0.35189</td></tr><tr><td>top3_acc</td><td>0.73694</td></tr></table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>val_loss</td><td>█▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▆▇▇▇▇█▇▇▆█▇██▇▇███████</td></tr><tr><td>val_prec</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇▆▇▇▇█▇▇███████</td></tr><tr><td>val_rec</td><td>▁▄▅▆▆▇▇▇▇▇█▇▇▆█▇███▇███████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▅▄▄▄▃▃▃▃▄▂▃▃▃▃▃▂▂▃▂▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▂</td></tr><tr><td>lr</td><td>██████████████████▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_prec</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_rec</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>top1_acc</td><td>▁</td></tr><tr><td>top3_acc</td><td>▁</td></tr></table><br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    <br/>Synced <strong style=\"color:#cdcd00\">Baseline Location -37.3375dB</strong>: <a href=\"https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/3cfszrbn\" target=\"_blank\">https://wandb.ai/sagarkaushik98/Beam%20Prediction/runs/3cfszrbn</a><br/>\n                "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"...Successfully finished last run (ID:3cfszrbn). Initializing new run:<br/><br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.29<br/>\n                Syncing run <strong style=\"color:#cdcd00\">run</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/sagarkaushik98/deep_dream\" target=\"_blank\">https://wandb.ai/sagarkaushik98/deep_dream</a><br/>\n                Run page: <a href=\"https://wandb.ai/sagarkaushik98/deep_dream/runs/36x32zsw\" target=\"_blank\">https://wandb.ai/sagarkaushik98/deep_dream/runs/36x32zsw</a><br/>\n                Run data is saved locally in <code>/kaggle/working/wandb/run-20210505_094454-36x32zsw</code><br/><br/>\n            "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n  warnings.warn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation sanity check: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65783e5cc36146b99fd1db27d6a143d2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n  warnings.warn(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Test Dataloader\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b65cff354f0490bb678a0d74a570ff5"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}